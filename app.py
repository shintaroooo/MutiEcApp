import streamlit as st
import requests
import os
from dotenv import load_dotenv
from openai import OpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationChain

# --- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ---
load_dotenv()

# --- LangChainç”¨ãƒ¢ãƒ‡ãƒ«ã¨ãƒ¡ãƒ¢ãƒªåˆæœŸåŒ– ---
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
language_model = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)
memory = ConversationBufferMemory()
conversation = ConversationChain(llm=language_model, memory=memory, verbose=False)

# --- OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆå•†å“æ¨è–¦ç”¨ï¼‰ ---
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --- è¨­å®š ---
RAKUTEN_APP_ID = os.getenv("RAKUTEN_APP_ID", "")
RAKUTEN_AFFILIATE_ID = os.getenv("RAKUTEN_AFFILIATE_ID", "")
YAHOO_APP_ID = os.getenv("YAHOO_APP_ID", "")
VC_AFFILIATE_ID = os.getenv("VC_AFFILIATE_ID", "")

AMAZON_DATA = [
    {"name": "Amazonã‚¤ãƒ¤ãƒ›ãƒ³C", "price": 8200, "rating": 4.6, "url": "#", "image": "https://via.placeholder.com/150"},
]

# --- APIå‘¼ã³å‡ºã—é–¢æ•°ï¼ˆæ¥½å¤©ãƒ»Yahooï¼‰ ---
def search_rakuten(query):
    url = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706"
    params = {
        "applicationId": RAKUTEN_APP_ID,
        "affiliateId": RAKUTEN_AFFILIATE_ID,
        "keyword": query,
        "format": "json",
        "hits": 10
    }
    res = requests.get(url, params=params)
    if res.status_code == 200:
        data = res.json()
        return [
            {
                "name": item["Item"]["itemName"],
                "price": item["Item"]["itemPrice"],
                "rating": item["Item"].get("reviewAverage", 0),
                "url": item["Item"]["affiliateUrl"],
                "image": item["Item"]["mediumImageUrls"][0]["imageUrl"]
            }
            for item in data.get("Items", [])
        ]
    else:
        return []

def search_yahoo(query):
    url = "https://shopping.yahooapis.jp/ShoppingWebService/V3/itemSearch"
    params = {
        "appid": YAHOO_APP_ID,
        "query": query,
        "affiliate_type": "vc",
        "affiliate_id": VC_AFFILIATE_ID,
        "results": 10
    }
    res = requests.get(url, params=params)
    if res.status_code == 200:
        data = res.json()
        return [
            {
                "name": item["name"],
                "price": item["price"],
                "rating": item.get("review", {}).get("rate", 0),
                "url": item["url"],
                "image": item["image"]["medium"]
            }
            for item in data.get("hits", [])
        ]
    else:
        return []

# --- ãŠã™ã™ã‚ç†ç”±ç”Ÿæˆ ---
def generate_recommendation(item_name, site, user_conditions):
    prompt = f"""
ã‚ãªãŸã¯å•†å“ã‚³ãƒ³ã‚·ã‚§ãƒ«ã‚¸ãƒ¥AIã§ã™ã€‚ä»¥ä¸‹ã®æ¡ä»¶ã‚’ã‚‚ã¨ã«ã€å•†å“ã‚’ãŠã™ã™ã‚ã™ã‚‹ç†ç”±ã‚’çŸ­ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¸Œæœ›æ¡ä»¶:
{user_conditions}

å•†å“å: {item_name}
è²©å£²ã‚µã‚¤ãƒˆ: {site}
"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temerature=0.5
    )
    return response.choices[0].message.content.strip()

# --- æ¡ä»¶æŠ½å‡ºï¼ˆLangChainã®memoryãƒ™ãƒ¼ã‚¹ï¼‰ ---
def extract_search_conditions():
    prompt = "ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¸Œæœ›ã‚’1ã¤ã®æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã¾ã¨ã‚ã¦ã€‚"
    return conversation.predict(input=prompt)

# --- Streamlit UI ---
st.set_page_config(page_title="AIãƒãƒ£ãƒƒãƒˆå•†å“æ¤œç´¢", layout="wide")
st.title("ğŸ§  AIã‚³ãƒ³ã‚·ã‚§ãƒ«ã‚¸ãƒ¥ã«å•†å“ã‚’ç›¸è«‡ã—ã‚ˆã†")

# --- ECã‚µã‚¤ãƒˆé¸æŠ ---
st.write("### ğŸ” æ¤œç´¢å¯¾è±¡ã®ECã‚µã‚¤ãƒˆã‚’é¸ã‚“ã§ãã ã•ã„")
selected_sites = st.multiselect("ECã‚µã‚¤ãƒˆã‚’é¸æŠ", ["æ¥½å¤©", "Yahoo", "Amazon"], default=["æ¥½å¤©", "Yahoo", "Amazon"])

if "chat_log" not in st.session_state:
    st.session_state.chat_log = []
    st.session_state.results_ready = False
    st.session_state.search_keyword = ""

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º ---
st.sidebar.header("ğŸ—’ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´")
if st.session_state.chat_log:
    for idx, msg in enumerate(st.session_state.chat_log, start=1):
        st.sidebar.markdown(f"**{idx}.** {msg}")
else:
    st.sidebar.info("ãƒãƒ£ãƒƒãƒˆã‚’é–‹å§‹ã™ã‚‹ã¨ã€ã“ã“ã«å±¥æ­´ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

# --- ãƒãƒ£ãƒƒãƒˆå…¥åŠ› ---
user_input = st.chat_input("ã©ã‚“ãªå•†å“ã‚’ãŠæ¢ã—ã§ã™ã‹ï¼Ÿï¼ˆä¾‹ï¼šè»½ãã¦å®‰ã„ãƒãƒ¼ãƒˆPCï¼‰")
if user_input:
    ai_response = conversation.predict(input=user_input)
    st.session_state.chat_log.append(user_input)
    st.chat_message("user").write(user_input)
    st.chat_message("assistant").write(ai_response)

# --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤ºï¼ˆå†è¡¨ç¤ºï¼‰ ---
for msg in st.session_state.chat_log:
    st.chat_message("user").write(msg)

# --- æ¡ä»¶ãŒååˆ†ã«ãªã£ãŸã‹ç¢ºèªãƒœã‚¿ãƒ³ ---
if len(st.session_state.chat_log) >= 3:
    if st.button("æ¡ä»¶ãŒæƒã„ã¾ã—ãŸï¼å•†å“ã‚’æ¢ã™ ğŸ”"):
        keyword = extract_search_conditions()
        st.session_state.search_keyword = keyword
        st.session_state.results_ready = True

# --- æ¤œç´¢ï¼†çµæœè¡¨ç¤º ---
if st.session_state.results_ready and st.session_state.search_keyword:
    query = st.session_state.search_keyword
    st.chat_message("assistant").write(f"æ¡ä»¶ã«åˆã†å•†å“ã‚’æ¢ã—ã¦ã„ã¾ã™... ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: ã€{query}ã€")

    all_items = []
    if "æ¥½å¤©" in selected_sites:
        all_items += search_rakuten(query)
    if "Yahoo" in selected_sites:
        all_items += search_yahoo(query)
    if "Amazon" in selected_sites:
        all_items += AMAZON_DATA

    top_items = sorted(all_items, key=lambda x: -x["rating"])[:3]

    st.write("### ğŸ† ãŠã™ã™ã‚å•†å“ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¸Šä½3ä»¶ï¼‰")
    for i, item in enumerate(top_items, start=1):
        recommendation = generate_recommendation(item["name"], ", ".join(selected_sites), query)
        st.markdown(f"**{i}. [{item['name']}]({item['url']})**")
        st.image(item["image"], width=150)
        st.write(f"ä¾¡æ ¼: Â¥{item['price']}  | è©•ä¾¡: â­ {item['rating']}")
        st.success(f"ãŠã™ã™ã‚ç†ç”±: {recommendation}")
        st.markdown("---")
